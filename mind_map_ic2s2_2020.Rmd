---
title: "Mind Map: Semi-Supervised Topic Extraction"
author: "Stefan Wojcik and Adam Hughes"
date: "`r format(Sys.Date())`"
output: 
  ioslides_presentation:
      logo: imgs/Twitter_Logo_Blue.png
  css: "newstyle.css"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning =  FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(cache = TRUE)

library(readr)
library(ggplot2)
library(dplyr)
library(knitr)
library(srvyr)
```

## Motivation
- No best practices for *classifying* topics within corpora
- Our goal: extract one or more predefined topics of interest
- Improve upon dictionary methods while preserving their efficiency 


## Dictionary approaches
 - Use an off-the-shelf lists of words that signify a concept of interest
 - Domain-sensitive and have may low reliability ([Barbera et al 2020](https://www.cambridge.org/core/journals/political-analysis/article/automated-text-classification-of-news-articles-a-practical-guide/10462DB284B1CD80C0FAE796AD786BC6), [Frimer 2019](http://www.jeremyfrimer.com/uploads/2/1/2/7/21278832/frimer__2019__jrp_.pdf))
 - Efficient but don't use any information from the corpus being analyzed

## Traditional Topic Modeling
- Method of dimensionality reduction: assumes that words are more likely to occur in certain topics relative to others
- Cannot select topic of interest at the outset
- Cannot predefine the level of generality (e.g. general topics versus subtopics). 
- Involves lots of manual 'tuning,' raising questions about researcher discretion and reproducibility

## An Alternative 

- Draw upon elements of dictionary methods and topic models via semi-supervised classification
- First used in [Bakshy, Messing, Adamic 2015](https://science.sciencemag.org/content/348/6239/1130.abstract)

## The 'Mind Map'
```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri("imgs/mind_map.png"), 
               width = 600)
```


## Algorithm

1. A set of 'seed' words that we know are about the topic. 
2. Apply positive label to any documents containing those words <!-- and coming from known sources NB - this part is unclear to me-->
3. Estimate a machine classification model to identify other words that co-occur with positive examples
4. Extrapolate the model to the entire dataset 

## Validation

1. Remove one of the seed words from the seed set
2. Assign positive labels only to documents containing that word <!-- unclear to me -->
3. Evaluate how well a model can recover the removed word with the remaining seed set
4. Rinse and repeat until all words are evaluated. 

## Example 1: Isolating Political News
- How to accurately classify political news without human coders?
- How to validate the accuracy of the classifier without ground truth?


## URLS/Tweets Data

- Limit analysis to the last 21 days
- 837,932 links to known misinfo domains (in EN)
- 894,938 links to any site (random tweets in EN containing a URL)


## Political words: Validation
```{r, echo=F}
recall = data_frame(Fragment = c("politi", "usnews", "world", "national", 
                             "state", "elect", "vote", "govern", "campaign", 
                             "war", "polic", "econ", "unemploy", "racis", 
                             "energy", "abortion", "educa", "healthcare", "immigration"), 
                Recall = c(.96, .45, .79, .85, .84, .85, .95, .98, 
                           .95, .98, .96, .88, .94, .95, .86, .98, .82, 
                           .84, .97), 
                Base_rate = c(.01, .0, .01, .01, .01, .01, .01, 0.0, 0.0, 0.0, 0.0, 
                              .01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0))
recall$Fragment = factor(recall$Fragment, levels = recall$Fragment[order(recall$Recall)])
qplot(data=recall, y=Fragment, x=Recall)
```
- Results: >95% accurate on test set

## Results: Political shares by type of link

**About 20%** of random URLs are about politics

**About 80%** of misinformation URLS were about politics

## Results: Political misinfo over time
**Over time patterns of political misinfo tend to match trends of politics**

```{r, echo=F}
htmltools::img(src = knitr::image_uri("imgs/misinfo_over_time.png"), 
               width = 600)
```

## Example 2: Classifying News into Subtopics
- Focus on sub-types of news content: economy, entertainment, immigration, sports 
- Supplement image analysis of who appears in different types of news photos

## Results of Main Analysis by Subtopics
```{r, echo=F}
htmltools::img(src = knitr::image_uri("imgs/pew_results.png"), 
               width = 600)
```


## Validation of Subtopic Classification
```{r, echo=F}
htmltools::img(src = knitr::image_uri("imgs/pew_validation.png"), 
               width = 600)
```

## THANK YOU!
